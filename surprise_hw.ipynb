{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Surprise homework\n",
    "1. Оценить по метрике RMSE с помощью функции cross_validate следующие алгоритмы:  \n",
    "прогнозирование случайного рейтинга на основе распределения всех рейтингов в наборе;\n",
    "user-based коллаборативную фильтрацию, метод kNN, k = 30, метрика косинуса; \n",
    "user-based коллаборативную фильтрацию, метод kNN, k = 30, метрика Mean Squared Difference ; \n",
    "user-based коллаборативную фильтрацию, метод kNN, k = 30, метрика корреляция Пирсона; \n",
    "SVD алгоритм.\n",
    "2. Для лучшего алгоритма по метрике RMSE рассчитать метрики precision@k and recall@k для k=5 и порога отсечения 3.52, усредненные по всем пользователям.\n",
    "3. Для заданного пользователя (номер в списке) c помощью лучшего алгоритма по метрике RMSE вывести топ-5 рекомендаций (те фильмы, для которых у пользователя нет оценки) с названиями, датой выхода и рейтингом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io \n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset \n",
    "from surprise import accuracy \n",
    "from surprise import get_dataset_dir\n",
    "\n",
    "from surprise.model_selection import cross_validate \n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise.model_selection import PredefinedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.dataset.DatasetAutoFolds at 0x2ab424886a0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=Dataset.load_builtin('ml-100k')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.trainset.Trainset at 0x2ab518c9190>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset, testset = train_test_split(data, test_size=.25)\n",
    "trainset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVD\n",
    "from surprise import NormalPredictor\n",
    "from surprise import KNNBasic\n",
    "from surprise import KNNBaseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Оценить по метрике RMSE с помощью функции cross_validate следующие алгоритмы:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "прогнозирование случайного рейтинга на основе распределения всех рейтингов в наборе; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.5255\n",
      "Evaluating RMSE of algorithm NormalPredictor on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.5241  1.5272  1.5144  1.5164  1.5222  1.5209  0.0048  \n",
      "Fit time          0.38    0.30    0.31    0.36    0.33    0.33    0.03    \n",
      "Test time         0.27    0.47    0.45    0.50    0.37    0.41    0.08    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.521]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array=[]\n",
    "algo1 = NormalPredictor()\n",
    "algo1.fit(trainset)\n",
    "predictions1 = algo1.test(testset)\n",
    "rmse1 = accuracy.rmse(predictions1)\n",
    "crvld1 = cross_validate(algo1, data, measures=['RMSE'], cv=5, verbose=True)\n",
    "array.append(round(crvld1['test_rmse'].mean(),3))\n",
    "array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "user-based коллаборативную фильтрацию, метод kNN, k = 30, метрика косинуса; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0248\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE of algorithm KNNBasic on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.0098  1.0283  1.0191  1.0208  1.0197  1.0195  0.0059  \n",
      "Fit time          4.16    4.37    3.90    4.07    4.27    4.15    0.16    \n",
      "Test time         7.50    7.66    7.17    7.34    7.50    7.44    0.17    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.521, 1.02]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo2=KNNBasic(k=30,sim_options={'name': 'cosine'})\n",
    "algo2.fit(trainset)\n",
    "predictions2 = algo2.test(testset)\n",
    "rmse2 = accuracy.rmse(predictions2)\n",
    "crvld2 = cross_validate(algo2, data, measures=['RMSE'], cv=5, verbose=True)\n",
    "array.append(round(crvld2['test_rmse'].mean(),3))\n",
    "array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "user-based коллаборативную фильтрацию, метод kNN, k = 30, метрика Mean Squared Difference ; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.9858\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE of algorithm KNNBasic on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9746  0.9750  0.9732  0.9786  0.9836  0.9770  0.0037  \n",
      "Fit time          1.17    1.28    1.31    1.18    1.66    1.32    0.18    \n",
      "Test time         7.61    7.72    7.31    7.99    7.86    7.70    0.23    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.521, 1.02, 0.977]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo3=KNNBasic(k=30,sim_options={'name': 'msd'})\n",
    "algo3.fit(trainset)\n",
    "predictions3 = algo3.test(testset)\n",
    "rmse3 = accuracy.rmse(predictions3)\n",
    "crvld3 = cross_validate(algo3, data, measures=['RMSE'], cv=5, verbose=True)\n",
    "array.append(round(crvld3['test_rmse'].mean(),3))\n",
    "array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "user-based коллаборативную фильтрацию, метод kNN, k = 30, метрика корреляция Пирсона;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0184\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE of algorithm KNNBasic on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.0171  1.0104  1.0133  1.0109  1.0071  1.0118  0.0033  \n",
      "Fit time          4.75    4.65    4.93    4.93    4.61    4.77    0.13    \n",
      "Test time         7.62    7.25    7.85    7.06    7.36    7.43    0.28    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.521, 1.02, 0.977, 1.012]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo4=KNNBasic(k=30,sim_options={'name': 'pearson_baseline','shrinkage': 0})\n",
    "algo4.fit(trainset)\n",
    "predictions4 = algo4.test(testset)\n",
    "rmse4 = accuracy.rmse(predictions4)\n",
    "crvld4 = cross_validate(algo4, data, measures=['RMSE'], cv=5, verbose=True)\n",
    "array.append(round(crvld4['test_rmse'].mean(),3))\n",
    "array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVD алгоритм."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9455\n",
      "Evaluating RMSE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9336  0.9411  0.9392  0.9389  0.9298  0.9365  0.0042  \n",
      "Fit time          10.84   10.94   10.65   10.94   10.79   10.83   0.11    \n",
      "Test time         0.55    0.36    0.30    0.58    0.32    0.42    0.12    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.521, 1.02, 0.977, 1.012, 0.936]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo5 = SVD()\n",
    "algo5.fit(trainset)\n",
    "predictions5 = algo5.test(testset)\n",
    "rmse5 = accuracy.rmse(predictions5)\n",
    "crvld5 = cross_validate(algo5, data, measures=['RMSE'], cv=5, verbose=True)\n",
    "array.append(round(crvld5['test_rmse'].mean(),3))\n",
    "array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<surprise.prediction_algorithms.random_pred.NormalPredictor object at 0x000002AB529ED550>, <surprise.prediction_algorithms.knns.KNNBasic object at 0x000002AB529EDA60>, <surprise.prediction_algorithms.knns.KNNBasic object at 0x000002AB529ED310>, <surprise.prediction_algorithms.knns.KNNBasic object at 0x000002AB529EDA90>, <surprise.prediction_algorithms.matrix_factorization.SVD object at 0x000002AB529ED880>] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "alg=[]\n",
    "alg.append(algo1)\n",
    "alg.append(algo2)\n",
    "alg.append(algo3)\n",
    "alg.append(algo4)\n",
    "alg.append(algo5)\n",
    "print(alg,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Для лучшего алгоритма по метрике RMSE рассчитать метрики precision@k and recall@k для k=5 и порога отсечения 3.52, усредненные по всем пользователям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.936 4 <surprise.prediction_algorithms.matrix_factorization.SVD object at 0x000002AB529ED880>\n"
     ]
    }
   ],
   "source": [
    "l=len(array)\n",
    "minimum=2\n",
    "for i in range(l):\n",
    "    if array[i]<=minimum: \n",
    "        minimum=array[i]\n",
    "        index=i\n",
    "best_algo=alg[index]\n",
    "print(minimum,index,best_algo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision@k: 0.736\n",
      "recall@k: 0.365\n"
     ]
    }
   ],
   "source": [
    "def precision_recall_at_k(predictions, k=10, threshold=3.52):\n",
    "    \"\"\"Return precision and recall at k metrics for each user\"\"\"\n",
    "\n",
    "    user_est_true = defaultdict(list)\n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "\n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "\n",
    "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "\n",
    "        n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold))\n",
    "                              for (est, true_r) in user_ratings[:k])\n",
    "\n",
    "\n",
    "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
    "\n",
    "\n",
    "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
    "\n",
    "    return precisions, recalls\n",
    "best_algo.fit(trainset)\n",
    "predictions = best_algo.test(testset)\n",
    "precisions, recalls = precision_recall_at_k(predictions, k=5, threshold=3.52)\n",
    "\n",
    "precisionk=round(sum(prec for prec in precisions.values()) / len(precisions),3)\n",
    "recallk=round(sum(rec for rec in recalls.values()) / len(recalls),3)\n",
    "print(\"precision@k:\",precisionk)\n",
    "print(\"recall@k:\",recallk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  3. Для заданного пользователя (номер в списке) c помощью лучшего алгоритма по метрике RMSE вывести топ-5 рекомендаций (те фильмы, для которых у пользователя нет оценки) с названиями, датой выхода и рейтингом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_number='21'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1|Toy Story (1995)|01-Jan-1995||http://us.imdb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2|GoldenEye (1995)|01-Jan-1995||http://us.imdb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3|Four Rooms (1995)|01-Jan-1995||http://us.imd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4|Get Shorty (1995)|01-Jan-1995||http://us.imd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5|Copycat (1995)|01-Jan-1995||http://us.imdb.c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1677</th>\n",
       "      <td>1678|Mat' i syn (1997)|06-Feb-1998||http://us....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1678</th>\n",
       "      <td>1679|B. Monkey (1998)|06-Feb-1998||http://us.i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1679</th>\n",
       "      <td>1680|Sliding Doors (1998)|01-Jan-1998||http://...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680</th>\n",
       "      <td>1681|You So Crazy (1994)|01-Jan-1994||http://u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>1682|Scream of Stone (Schrei aus Stein) (1991)...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1682 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      0\n",
       "0     1|Toy Story (1995)|01-Jan-1995||http://us.imdb...\n",
       "1     2|GoldenEye (1995)|01-Jan-1995||http://us.imdb...\n",
       "2     3|Four Rooms (1995)|01-Jan-1995||http://us.imd...\n",
       "3     4|Get Shorty (1995)|01-Jan-1995||http://us.imd...\n",
       "4     5|Copycat (1995)|01-Jan-1995||http://us.imdb.c...\n",
       "...                                                 ...\n",
       "1677  1678|Mat' i syn (1997)|06-Feb-1998||http://us....\n",
       "1678  1679|B. Monkey (1998)|06-Feb-1998||http://us.i...\n",
       "1679  1680|Sliding Doors (1998)|01-Jan-1998||http://...\n",
       "1680  1681|You So Crazy (1994)|01-Jan-1994||http://u...\n",
       "1681  1682|Scream of Stone (Schrei aus Stein) (1991)...\n",
       "\n",
       "[1682 rows x 1 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = '/Users/79523/.surprise_data/ml-100k/ml-100k/u.item'\n",
    "data_df = pd.read_csv(data_path, sep='\\t',encoding='ISO-8859-1', header = None)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('357', 4.36800248132644), ('191', 4.3496418357749045), ('89', 4.2916095083835435), ('180', 4.278142560897888), ('657', 4.273553557230006)]\n",
      "Пользователь: 21 \n",
      "Рекомендация: ['357', '191', '89', '180', '657']\n",
      "357 (\"One Flew Over the Cuckoo's Nest (1975)\", \"01-Jan-1975\")  4.368\n",
      "191 (\"Amadeus (1984)\", \"01-Jan-1984\")  4.35\n",
      "89 (\"Blade Runner (1982)\", \"01-Jan-1982\")  4.292\n",
      "180 (\"Apocalypse Now (1979)\", \"01-Jan-1979\")  4.278\n",
      "657 (\"Manchurian Candidate, The (1962)\", \"01-Jan-1962\")  4.274\n"
     ]
    }
   ],
   "source": [
    "best_algo.fit(trainset)\n",
    "testset = trainset.build_anti_testset()\n",
    "predictions = best_algo.test(testset)\n",
    "\n",
    "def get_top_n(predictions, n=5):\n",
    "    \"\"\"Return the top-N recommendation for each user from a set of predictions.\n",
    "\n",
    "    Args:\n",
    "        predictions(list of Prediction objects): The list of predictions, as\n",
    "            returned by the test method of an algorithm.\n",
    "        n(int): The number of recommendation to output for each user. Default\n",
    "            is 10.\n",
    "\n",
    "    Returns:\n",
    "    A dict where keys are user (raw) ids and values are lists of tuples:\n",
    "        [(raw item id, rating estimation), ...] of size n.\n",
    "    \"\"\"\n",
    "\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "\n",
    "    return top_n\n",
    "top_n = get_top_n(predictions, n=5)\n",
    "\n",
    "recommended_films=list()\n",
    "for uid, user_ratings in top_n.items():\n",
    "    if uid == var_number:\n",
    "        for iid,_ in user_ratings:\n",
    "            recommended_films.append(iid)\n",
    "            ratings = user_ratings\n",
    "\n",
    "ratings = dict(ratings)  \n",
    "\n",
    "print(\"Пользователь:\",var_number,\"\\nРекомендация:\", recommended_films)\n",
    "\n",
    "def read_item_names():\n",
    "    file_name = get_dataset_dir() + '/ml-100k/ml-100k/u.item'\n",
    "    rid_to_name = {}\n",
    "    with io.open(file_name, 'r', encoding='ISO-8859-1') as f:\n",
    "        for line in f:\n",
    "            line = line.split('|')\n",
    "            rid_to_name[line[0]] = line[0]+' (\"'+line[1]+'\", \"'+line[2]+'\") '\n",
    "    return rid_to_name\n",
    "rid_to_name= read_item_names()\n",
    "\n",
    "file=open('rez_file_21.txt','w')\n",
    "file.write('User '+str(var_number)+'\\n')\n",
    "\n",
    "for i in recommended_films:\n",
    "    res_list=rid_to_name[i]+' '+str(round((ratings[i]),3))\n",
    "    file.write(res_list+'\\n')\n",
    "    print(res_list)\n",
    "    \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
