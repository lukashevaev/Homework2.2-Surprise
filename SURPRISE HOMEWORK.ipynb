{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Surprise homework\n",
    "1. Оценить по метрике RMSE с помощью функции cross_validate следующие алгоритмы:  \n",
    "прогнозирование случайного рейтинга на основе распределения всех рейтингов в наборе;\n",
    "user-based коллаборативную фильтрацию, метод kNN, k = 30, метрика косинуса; \n",
    "user-based коллаборативную фильтрацию, метод kNN, k = 30, метрика Mean Squared Difference ; \n",
    "user-based коллаборативную фильтрацию, метод kNN, k = 30, метрика корреляция Пирсона; \n",
    "SVD алгоритм.\n",
    "2. Для лучшего алгоритма по метрике RMSE рассчитать метрики precision@k and recall@k для k=5 и порога отсечения 3.52, усредненные по всем пользователям.\n",
    "3. Для заданного пользователя (номер в списке) c помощью лучшего алгоритма по метрике RMSE вывести топ-5 рекомендаций (те фильмы, для которых у пользователя нет оценки) с названиями, датой выхода и рейтингом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io \n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# используйте полезные функции из FAQ\n",
    "\n",
    "from surprise import Dataset \n",
    "from surprise import accuracy \n",
    "from surprise import get_dataset_dir\n",
    "\n",
    "from surprise.model_selection import cross_validate \n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise.model_selection import PredefinedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.dataset.DatasetAutoFolds at 0x202f9a9f940>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=Dataset.load_builtin('ml-100k')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.trainset.Trainset at 0x202e9a657c0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "trainset, testset = train_test_split(data, test_size=.25)\n",
    "trainset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# внимательно изучите документацию по метрикам и алгоритмам\n",
    "from surprise import SVD\n",
    "from surprise import NormalPredictor\n",
    "from surprise import KNNBasic\n",
    "from surprise import KNNBaseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Оценить по метрике RMSE с помощью функции cross_validate следующие алгоритмы:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "прогнозирование случайного рейтинга на основе распределения всех рейтингов в наборе; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.5214\n",
      "Evaluating RMSE of algorithm NormalPredictor on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.5185  1.5175  1.5184  1.5234  1.5177  1.5191  0.0022  \n",
      "Fit time          0.28    0.28    0.30    0.29    0.29    0.29    0.00    \n",
      "Test time         0.26    0.38    0.42    0.26    0.36    0.34    0.06    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.519]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array=[]\n",
    "#\n",
    "algo1 = NormalPredictor()\n",
    "algo1.fit(trainset)\n",
    "# Than predict ratings for all pairs (u, i) that are in the training set.\n",
    "predictions1 = algo1.test(testset)\n",
    "#точность метрики\n",
    "rmse1 = accuracy.rmse(predictions1)\n",
    "crvld1 = cross_validate(algo1, data, measures=['RMSE'], cv=5, verbose=True)\n",
    "#берем среднее по всем ретингам в наборе test_rmse\n",
    "array.append(round(crvld1['test_rmse'].mean(),3))\n",
    "array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "user-based коллаборативную фильтрацию, метод kNN, k = 30, метрика косинуса; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0233\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE of algorithm KNNBasic on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.0168  1.0207  1.0237  1.0157  1.0188  1.0192  0.0029  \n",
      "Fit time          4.43    3.78    3.78    3.67    3.66    3.86    0.29    \n",
      "Test time         8.47    6.81    6.98    6.53    6.61    7.08    0.71    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.519, 1.019]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo2=KNNBasic(k=30,sim_options={'name': 'cosine'})\n",
    "algo2.fit(trainset)\n",
    "predictions2 = algo2.test(testset)\n",
    "rmse2 = accuracy.rmse(predictions2)\n",
    "crvld2 = cross_validate(algo2, data, measures=['RMSE'], cv=5, verbose=True)\n",
    "#продложаем добавлять результаты\n",
    "array.append(round(crvld2['test_rmse'].mean(),3))\n",
    "array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "user-based коллаборативную фильтрацию, метод kNN, k = 30, метрика Mean Squared Difference ; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.9826\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE of algorithm KNNBasic on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9789  0.9768  0.9749  0.9785  0.9796  0.9777  0.0017  \n",
      "Fit time          1.12    1.15    1.15    1.14    1.18    1.15    0.02    \n",
      "Test time         6.60    7.10    7.14    6.70    6.64    6.84    0.23    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.519, 1.019, 0.978]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo3=KNNBasic(k=30,sim_options={'name': 'msd'})\n",
    "algo3.fit(trainset)\n",
    "predictions3 = algo3.test(testset)\n",
    "rmse3 = accuracy.rmse(predictions3)\n",
    "crvld3 = cross_validate(algo3, data, measures=['RMSE'], cv=5, verbose=True)\n",
    "#продложаем добавлять результаты\n",
    "array.append(round(crvld3['test_rmse'].mean(),3))\n",
    "array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "user-based коллаборативную фильтрацию, метод kNN, k = 30, метрика корреляция Пирсона;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0155\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE of algorithm KNNBasic on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.0060  1.0102  1.0180  1.0086  1.0074  1.0100  0.0042  \n",
      "Fit time          4.27    4.38    4.37    4.50    4.41    4.39    0.07    \n",
      "Test time         6.40    6.57    6.33    6.65    6.66    6.52    0.13    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.519, 1.019, 0.978, 1.01]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo4=KNNBasic(k=30,sim_options={'name': 'pearson_baseline','shrinkage': 0})\n",
    "algo4.fit(trainset)\n",
    "predictions4 = algo4.test(testset)\n",
    "rmse4 = accuracy.rmse(predictions4)\n",
    "crvld4 = cross_validate(algo4, data, measures=['RMSE'], cv=5, verbose=True)\n",
    "#продложаем добавлять результаты\n",
    "array.append(round(crvld4['test_rmse'].mean(),3))\n",
    "array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVD алгоритм."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9452\n",
      "Evaluating RMSE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9325  0.9330  0.9418  0.9377  0.9320  0.9354  0.0038  \n",
      "Fit time          10.00   10.66   10.24   10.20   10.70   10.36   0.27    \n",
      "Test time         0.29    0.30    0.52    0.29    0.31    0.34    0.09    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.519, 1.019, 0.978, 1.01, 0.935]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo5 = SVD()\n",
    "algo5.fit(trainset)\n",
    "predictions5 = algo5.test(testset)\n",
    "rmse5 = accuracy.rmse(predictions5)\n",
    "crvld5 = cross_validate(algo5, data, measures=['RMSE'], cv=5, verbose=True)\n",
    "#продложаем добавлять результаты\n",
    "array.append(round(crvld5['test_rmse'].mean(),3))\n",
    "array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<surprise.prediction_algorithms.random_pred.NormalPredictor object at 0x00000202F9FDE4F0>, <surprise.prediction_algorithms.knns.KNNBasic object at 0x00000202F9FDEA90>, <surprise.prediction_algorithms.knns.KNNBasic object at 0x00000202E9A5EA30>, <surprise.prediction_algorithms.knns.KNNBasic object at 0x00000202F9FDE190>, <surprise.prediction_algorithms.matrix_factorization.SVD object at 0x00000202E9A5E640>] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "alg=[]\n",
    "alg.append(algo1)\n",
    "alg.append(algo2)\n",
    "alg.append(algo3)\n",
    "alg.append(algo4)\n",
    "alg.append(algo5)\n",
    "print(alg,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Для лучшего алгоритма по метрике RMSE рассчитать метрики precision@k and recall@k для k=5 и порога отсечения 3.52, усредненные по всем пользователям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.935 4 <surprise.prediction_algorithms.matrix_factorization.SVD object at 0x00000202E9A5E640>\n"
     ]
    }
   ],
   "source": [
    "#ищем лучший алгоритм\n",
    "l=len(array)\n",
    "min=2\n",
    "for i in range(l):\n",
    "    if array[i]<=min: \n",
    "        min=array[i]\n",
    "        index=i\n",
    "best_algo=alg[index]\n",
    "print(min,index,best_algo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision@k: 0.747\n",
      "recall@k: 0.373\n"
     ]
    }
   ],
   "source": [
    "#собственно алгоритм с FAQ\n",
    "\n",
    "def precision_recall_at_k(predictions, k=10, threshold=3.52):\n",
    "    \"\"\"Return precision and recall at k metrics for each user\"\"\"\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    user_est_true = defaultdict(list)\n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "\n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "\n",
    "        # Sort user ratings by estimated value\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        # Number of relevant items\n",
    "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "\n",
    "        # Number of recommended items in top k\n",
    "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "\n",
    "        # Number of relevant and recommended items in top k\n",
    "        n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold))\n",
    "                              for (est, true_r) in user_ratings[:k])\n",
    "\n",
    "        # Precision@K: Proportion of recommended items that are relevant\n",
    "        # When n_rec_k is 0, Precision is undefined. We here set it to 0.\n",
    "\n",
    "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
    "\n",
    "        # Recall@K: Proportion of relevant items that are recommended\n",
    "        # When n_rel is 0, Recall is undefined. We here set it to 0.\n",
    "\n",
    "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
    "\n",
    "    return precisions, recalls\n",
    "best_algo.fit(trainset)\n",
    "predictions = best_algo.test(testset)\n",
    "precisions, recalls = precision_recall_at_k(predictions, k=5, threshold=3.52)\n",
    "        # Precision and recall can then be averaged over all users\n",
    "precisionk=round(sum(prec for prec in precisions.values()) / len(precisions),3)\n",
    "recallk=round(sum(rec for rec in recalls.values()) / len(recalls),3)\n",
    "print(\"precision@k:\",precisionk)\n",
    "print(\"recall@k:\",recallk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  3. Для заданного пользователя (номер в списке) c помощью лучшего алгоритма по метрике RMSE вывести топ-5 рекомендаций (те фильмы, для которых у пользователя нет оценки) с названиями, датой выхода и рейтингом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_number='21'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1|Toy Story (1995)|01-Jan-1995||http://us.imdb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2|GoldenEye (1995)|01-Jan-1995||http://us.imdb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3|Four Rooms (1995)|01-Jan-1995||http://us.imd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4|Get Shorty (1995)|01-Jan-1995||http://us.imd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5|Copycat (1995)|01-Jan-1995||http://us.imdb.c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1677</th>\n",
       "      <td>1678|Mat' i syn (1997)|06-Feb-1998||http://us....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1678</th>\n",
       "      <td>1679|B. Monkey (1998)|06-Feb-1998||http://us.i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1679</th>\n",
       "      <td>1680|Sliding Doors (1998)|01-Jan-1998||http://...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680</th>\n",
       "      <td>1681|You So Crazy (1994)|01-Jan-1994||http://u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>1682|Scream of Stone (Schrei aus Stein) (1991)...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1682 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      0\n",
       "0     1|Toy Story (1995)|01-Jan-1995||http://us.imdb...\n",
       "1     2|GoldenEye (1995)|01-Jan-1995||http://us.imdb...\n",
       "2     3|Four Rooms (1995)|01-Jan-1995||http://us.imd...\n",
       "3     4|Get Shorty (1995)|01-Jan-1995||http://us.imd...\n",
       "4     5|Copycat (1995)|01-Jan-1995||http://us.imdb.c...\n",
       "...                                                 ...\n",
       "1677  1678|Mat' i syn (1997)|06-Feb-1998||http://us....\n",
       "1678  1679|B. Monkey (1998)|06-Feb-1998||http://us.i...\n",
       "1679  1680|Sliding Doors (1998)|01-Jan-1998||http://...\n",
       "1680  1681|You So Crazy (1994)|01-Jan-1994||http://u...\n",
       "1681  1682|Scream of Stone (Schrei aus Stein) (1991)...\n",
       "\n",
       "[1682 rows x 1 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = '/Users/79523/.surprise_data/ml-100k/ml-100k/u.item'\n",
    "data_df = pd.read_csv(data_path, sep='\\t',encoding='ISO-8859-1', header = None)\n",
    "# data_df.iloc[20]\n",
    "data_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пользователь: 21 \n",
      "Рекомендация: ['313', '89', '654', '285', '603']\n",
      "313 (\"Titanic (1997)\", \"01-Jan-1997\")  4.446\n",
      "89 (\"Blade Runner (1982)\", \"01-Jan-1982\")  4.351\n",
      "654 (\"Chinatown (1974)\", \"01-Jan-1974\")  4.329\n",
      "285 (\"Secrets & Lies (1996)\", \"04-Oct-1996\")  4.299\n",
      "603 (\"Rear Window (1954)\", \"01-Jan-1954\")  4.254\n"
     ]
    }
   ],
   "source": [
    "#Лучшим алгоритом выполняем поиск 5 рекомендаций\n",
    "\n",
    "best_algo.fit(trainset)\n",
    "#фильмы у которых нет оценки\n",
    "testset = trainset.build_anti_testset()\n",
    "predictions = best_algo.test(testset)\n",
    "\n",
    "def get_top_n(predictions, n=5):\n",
    "    \"\"\"Return the top-N recommendation for each user from a set of predictions.\n",
    "\n",
    "    Args:\n",
    "        predictions(list of Prediction objects): The list of predictions, as\n",
    "            returned by the test method of an algorithm.\n",
    "        n(int): The number of recommendation to output for each user. Default\n",
    "            is 10.\n",
    "\n",
    "    Returns:\n",
    "    A dict where keys are user (raw) ids and values are lists of tuples:\n",
    "        [(raw item id, rating estimation), ...] of size n.\n",
    "    \"\"\"\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "\n",
    "    return top_n\n",
    "\n",
    "top_n = get_top_n(predictions, n=5)\n",
    "# var_number='21'\n",
    "# print(user_ratings)\n",
    "# Выбираем только своего пользователя\n",
    "for uid, user_ratings in top_n.items():\n",
    "    if uid == var_number:\n",
    "        films_for_my_user = [iid for (iid, _) in user_ratings]\n",
    "        rate = user_ratings\n",
    "#         print(rate)\n",
    "#потом нам понадобится рейтинг\n",
    "\n",
    "rate = dict(rate)        \n",
    "print(\"Пользователь:\",var_number,\"\\nРекомендация:\", films_for_my_user)\n",
    "\n",
    "#нам нужны названия, дата выхода и рейтинг фильмов\n",
    "\n",
    "def read_item_names():\n",
    "    file_name = get_dataset_dir() + '/ml-100k/ml-100k/u.item'\n",
    "    rid_to_name = {}\n",
    "    with io.open(file_name, 'r', encoding='ISO-8859-1') as f:\n",
    "        for line in f:\n",
    "            line = line.split('|')\n",
    "            rid_to_name[line[0]] = line[0]+' (\"'+line[1]+'\", \"'+line[2]+'\") '\n",
    "    return rid_to_name\n",
    "rid_to_name= read_item_names()\n",
    "\n",
    "file=open('rez_file_21.txt','w')\n",
    "file.write('User '+str(var_number)+'\\n')\n",
    "\n",
    "for i in films_for_my_user:\n",
    "    res_list=rid_to_name[i]+' '+str(round((rate[i]),3))\n",
    "    file.write(res_list+'\\n')\n",
    "    print(res_list)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid file path or buffer object type: <class 'surprise.dataset.DatasetAutoFolds'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-8641948cc89a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdata_df\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\79523\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    684\u001b[0m     )\n\u001b[0;32m    685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\79523\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    432\u001b[0m     \u001b[1;31m# though mypy handling of conditional imports is difficult.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m     \u001b[1;31m# See https://github.com/python/mypy/issues/1297\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 434\u001b[1;33m     fp_or_buf, _, compression, should_close = get_filepath_or_buffer(\n\u001b[0m\u001b[0;32m    435\u001b[0m         \u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m     )\n",
      "\u001b[1;32mc:\\users\\79523\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_filepath_or_buffer\u001b[1;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[0;32m    241\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"Invalid file path or buffer object type: {type(filepath_or_buffer)}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 243\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    244\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid file path or buffer object type: <class 'surprise.dataset.DatasetAutoFolds'>"
     ]
    }
   ],
   "source": [
    "data_df = pd.read_csv(data)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate precision@k and recall@k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# обратите внимание на функцию build_anti_testset\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
